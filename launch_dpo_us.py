#!/usr/bin/env python
"""
Load the preference dataset generated by generate_preference_dataset.py,
filter to high-signal rows, convert to Together AI DPO format, and launch
a DPO fine-tuning job on the US SFT checkpoint.

Requires: pip install together datasets
Env: TOGETHER_API_KEY (required), WANDB_API_KEY (optional)
"""

import argparse
import json
import os
import tempfile

from datasets import load_dataset
from together import Together

HF_PREF_REPO = os.environ.get("HF_PREF_REPO", "slingshot/multiwoz-2.1-user-pref-v1")
MODEL = "slingshot/Meta-Llama-3.1-70B-Instruct-Reference-multiwoz-us-sft-4dcc3672"


def main():
    parser = argparse.ArgumentParser(description="Launch US DPO on Together AI")
    parser.add_argument(
        "--dataset",
        default=HF_PREF_REPO,
        help=f"HuggingFace preference dataset (default: {HF_PREF_REPO})",
    )
    parser.add_argument(
        "--split",
        default="train",
        help="Dataset split to use (default: train)",
    )
    parser.add_argument(
        "--suffix",
        default="multiwoz-us-dial-it1",
        help="Suffix for the fine-tuned model name",
    )
    parser.add_argument(
        "--dpo-beta",
        type=float,
        default=0.1,
        help="DPO beta parameter (default: 0.1)",
    )
    parser.add_argument(
        "--top-margin-frac",
        type=float,
        default=0.5,
        help="After chosen>0/rejected<0 filter, keep this fraction of pairs with highest (chosen-rejected) margin (default: 0.5)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Prepare and check data only; do not upload or create job",
    )
    args = parser.parse_args()

    api_key = os.environ.get("TOGETHER_API_KEY")
    if not api_key and not args.dry_run:
        raise SystemExit("Set TOGETHER_API_KEY to launch jobs.")

    print(f"Loading preference dataset: {args.dataset} (split={args.split})")
    ds = load_dataset(args.dataset, split=args.split)
    print(f"  Loaded {len(ds)} examples")

    # Filter: keep only rows where chosen_reward > 0 and rejected_reward < 0
    ds = ds.filter(lambda x: x["chosen_reward"] > 0 and x["rejected_reward"] < 0)
    print(f"  After filtering (chosen > 0, rejected < 0): {len(ds)} examples")

    # Keep only top fraction by margin (chosen_reward - rejected_reward)
    if args.top_margin_frac < 1.0 and len(ds) > 0:
        margin = [c - r for c, r in zip(ds["chosen_reward"], ds["rejected_reward"])]
        ds = ds.add_column("_margin", margin)
        ds = ds.sort("_margin", reverse=True)
        n_keep = max(1, int(len(ds) * args.top_margin_frac))
        ds = ds.select(range(n_keep))
        ds = ds.remove_columns("_margin")
        print(
            f"  After keeping top {args.top_margin_frac * 100:.0f}%% by margin: {len(ds)} examples"
        )

    if len(ds) == 0:
        raise SystemExit("No examples remain after filtering.")

    def to_dpo_row(example):
        return {
            "input": {"messages": example["messages"]},
            "preferred_output": [example["chosen"]],
            "non_preferred_output": [example["rejected"]],
        }

    with tempfile.NamedTemporaryFile(
        mode="w", suffix=".jsonl", delete=False, encoding="utf-8"
    ) as f:
        path = f.name
        for i in range(len(ds)):
            row = to_dpo_row(ds[i])
            f.write(json.dumps(row, ensure_ascii=False) + "\n")

    print(f"  Wrote JSONL to {path}")

    # Preview first example
    with open(path) as f:
        first = json.loads(f.readline())
    n_ctx = len(first["input"]["messages"])
    pref_preview = first["preferred_output"][0]["content"][:80]
    print(f"  Example: {n_ctx} context msgs, preferred: {pref_preview}...")

    if args.dry_run:
        print("Dry run: skipping upload and job creation.")
        os.unlink(path)
        return

    client = Together(api_key=api_key)

    from together.utils import check_file

    report = check_file(path)
    print("  File check:", report.get("message", report))
    if not report.get("is_check_passed", False):
        os.unlink(path)
        raise SystemExit("File check failed. Fix data format and retry.")

    print("  Uploading to Together AI ...")
    upload_resp = client.files.upload(path, purpose="fine-tune", check=True)
    os.unlink(path)
    training_file_id = upload_resp.id
    print(f"  Training file ID: {training_file_id}")

    wandb_key = os.environ.get("WANDB_API_KEY")
    create_kw = {
        "training_file": training_file_id,
        "from_checkpoint": MODEL,
        "n_epochs": 1,
        "n_checkpoints": 1,
        "learning_rate": 5e-6,
        "lr_scheduler_type": "linear",
        "min_lr_ratio": 0.0,
        "training_method": "dpo",
        "dpo_beta": args.dpo_beta,
        "wandb_project_name": "DIAL",
        "suffix": args.suffix,
    }
    if wandb_key:
        create_kw["wandb_api_key"] = wandb_key

    print("  Creating DPO fine-tuning job ...")
    print(f"  Model: {MODEL}")
    print(f"  DPO beta: {args.dpo_beta}")
    ft_resp = client.fine_tuning.create(**create_kw)
    print(f"  Job ID: {ft_resp.id}")
    print(f"  Status: {getattr(ft_resp, 'status', 'N/A')}")
    print("  Monitor: client.fine_tuning.retrieve(id=%r)" % ft_resp.id)


if __name__ == "__main__":
    main()
